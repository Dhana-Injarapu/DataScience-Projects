{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f6b0357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycrf in c:\\users\\dhana\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: sklearn-crfsuite in c:\\users\\dhana\\anaconda3\\lib\\site-packages (0.3.6)\n",
      "Requirement already satisfied: six in c:\\users\\dhana\\anaconda3\\lib\\site-packages (from sklearn-crfsuite) (1.16.0)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in c:\\users\\dhana\\anaconda3\\lib\\site-packages (from sklearn-crfsuite) (0.9.9)\n",
      "Requirement already satisfied: tabulate in c:\\users\\dhana\\anaconda3\\lib\\site-packages (from sklearn-crfsuite) (0.8.9)\n",
      "Requirement already satisfied: tqdm>=2.0 in c:\\users\\dhana\\anaconda3\\lib\\site-packages (from sklearn-crfsuite) (4.64.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dhana\\anaconda3\\lib\\site-packages (from tqdm>=2.0->sklearn-crfsuite) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pycrf\n",
    "!pip install sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a2b896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de3e3321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filename):\n",
    "    input_file=open(filename,'r')\n",
    "    file_content=input_file.readlines()\n",
    "    input_file.close()\n",
    "    out_lines=[]# to store list of sequences\n",
    "    line_content=\"\"\n",
    "    for word in file_content:\n",
    "        word=word.strip()\n",
    "        if word ==\"\":#if line is empty add sent out_lines\n",
    "            out_lines.append(line_content)\n",
    "            line_content=''\n",
    "        else:    \n",
    "            if line_content:\n",
    "                line_content+=\" \"+word # for non empty word add word to previous word with space\n",
    "            else:\n",
    "                line_content=word # first time no need to add space\n",
    "            \n",
    "    return out_lines      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3b6920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sent=process_file('train_sent')\n",
    "train_label=process_file('train_label')\n",
    "test_sent=process_file('test_sent')\n",
    "test_label=process_file('test_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48d045be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All live births > or = 23 weeks at the University of Vermont in 1995 ( n = 2395 ) were retrospectively analyzed for delivery route , indication for cesarean , gestational age , parity , and practice group ( to reflect risk status )', 'The total cesarean rate was 14.4 % ( 344 of 2395 ) , and the primary rate was 11.4 % ( 244 of 2144 )', 'Abnormal presentation was the most common indication ( 25.6 % , 88 of 344 )', \"The `` corrected '' cesarean rate ( maternal-fetal medicine and transported patients excluded ) was 12.4 % ( 273 of 2194 ) , and the `` corrected '' primary rate was 9.6 % ( 190 of 1975 )\", \"Arrest of dilation was the most common indication in both `` corrected '' subgroups ( 23.4 and 24.6 % , respectively )\", 'Cesarean rates at tertiary care hospitals should be compared with rates at community hospitals only after correcting for dissimilar patient groups or gestational age', 'In the third trimester , the amniotic fluid index ( AFI ) may be affected by maternal fluid status', 'We hypothesize that as temperature increases there would be a concomitant decrease in AFI', \"From June 11 to August 16 , 1993 , during a period of unusual high heat , 42 women with singleton pregnancies between 27 and 40 weeks ' gestation undergoing serial antenatal testing had AFI determinations recorded at least weekly\", 'The daily high ambient temperature in our urban area was subsequently obtained']\n",
      "\n",
      "\n",
      "\n",
      "['O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O']\n",
      "\n",
      "\n",
      "\n",
      "['Furthermore , when all deliveries were analyzed , regardless of risk status but limited to gestational age > or = 36 weeks , the rates did not change ( 12.6 % , 280 of 2214 ; primary 9.2 % , 183 of 1994 )', 'As the ambient temperature increases , there is an increase in insensible fluid loss and the potential for dehydration', 'The daily high temperature ranged from 71 to 104 degrees F and AFI values ranged from 1.7 to 24.7 cm during the study period', 'There was a significant correlation between the 2- , 3- , and 4-day mean temperature and AFI , with the 4-day mean being the most significant ( r = 0.31 , p & # 60 ; 0.001 )', 'Fluctuations in ambient temperature are inversely correlated to changes in AFI', 'This study tested the hypothesis that to reduce the rate of macrosomic infants in gestational diabetes cases , good glycemic control should be initiated before 34 completed gestational weeks', \"In the `` early '' and `` late '' groups , mean gestational age at the beginning of treatment was 30.0 +/- 3.8 and 36.2 +/- 1.2 weeks , and duration of treatment was 9.6 +/- 4.1 and 3.7 +/- 1.8 weeks , respectively\", \"The rate of macrosomic and large-for-gestational-age infants were 5 and 11 % , respectively , in the early group as compared to 25 and 29 % in the `` late '' group ( p & # 60 ; 0.05 )\", 'In our study , we specifically analyzed the role played by advanced maternal age and sonographically discovered abnormalities in the detection of autosomal trisomies', 'All together , 27 fetuses had this disorder , representing 28.7 % ( 27 of 94 ) of all cytogenetic aberrations detected at our center over the same period']\n",
      "\n",
      "\n",
      "\n",
      "['O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O', 'O O O O O O O O O O O O O O O O O O O O O O D D', 'O O O O O O O O O O O O O O O O O O O D D O O O O O O O O']\n"
     ]
    }
   ],
   "source": [
    "print(train_sent[:10])\n",
    "print(\"\\n\\n\")\n",
    "print(train_label[:10])\n",
    "print(\"\\n\\n\")\n",
    "print(test_sent[:10])\n",
    "print(\"\\n\\n\")\n",
    "print(test_label[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e12e474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Sentence: Down syndrome ( 12 cases ) and Edward syndrome ( 11 cases ) were the most common trisomies , while 4 cases of Patau syndrome were also diagnosed\n",
      "Labels: D D O O O O O D D O O O O O O O O D O O O O O D D O O O \n",
      "\n",
      "\n",
      "Sentence: Down syndrome fetuses ( 41.7 % ) had prenatally detected sonographic anomalies , 63.6 % for Edward syndrome , and all fetuses with Patau syndrome ( 4 of 4 ) showed abnormal sonographic signs\n",
      "Labels: D D O O O O O O O O O O O O O O D D O O O O O D D O O O O O O O O O \n",
      "\n",
      "\n",
      "Sentence: Trisomy 21 presented with the following features : hydramnios , complex malformations , pyelectasis , and duodenal atresia\n",
      "Labels: D D O O O O O O O O O O O D O O D D \n",
      "\n",
      "\n",
      "Sentence: Signs observed in fetuses with trisomy 13 were : hydrocephalus , intrauterine growth retardation , oligoanhydramnios , complex malformations , severe fetal bradycardia and hydronephrosis\n",
      "Labels: O O O O O D D O O O O O O O O O O O O O O O D O D \n",
      "\n",
      "\n",
      "Sentence: Fifty-three triplet pregnancies between 1986 and 1993 at The New York Hospital-Cornell Medical Center were reviewed\n",
      "Labels: O O O O O O O O O O O O O O O O \n",
      "\n",
      "\n",
      "==================================================\n",
      "==================================================\n",
      "TEST\n",
      "Sentence: Reduction of vasoreactivity and thrombogenicity with laser-thermal angioplasty : comparison with balloon angioplasty\n",
      "Labels: O O D O D O T T O O O T T \n",
      "\n",
      "\n",
      "Sentence: Effects of ultrasound energy on total peripheral artery occlusions : initial angiographic and angioscopic results .\n",
      "Labels: O O T T O D D D D O O O O O O O \n",
      "\n",
      "\n",
      "Sentence: High-dose chemotherapy with autologous stem-cell support for epithelial ovarian cancer\n",
      "Labels: T T T T T T O D D D \n",
      "\n",
      "\n",
      "Sentence: `` Tandem '' high-dose chemoradiotherapy with autologous stem-cell support in the treatment of newly diagnosed or responsive multiple myeloma\n",
      "Labels: T T T T T T T T T O O O O O O O O D D \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN\")\n",
    "for i in range(20,25):\n",
    "    print(\"Sentence:\", train_sent[i])\n",
    "    print(\"Labels:\", train_label[i], \"\\n\\n\")\n",
    "print(\"=\"*50)\n",
    "print(\"=\"*50)\n",
    "print(\"TEST\")\n",
    "for i in range(-5,-1):\n",
    "    print(\"Sentence:\", test_sent[i])\n",
    "    print(\"Labels:\", test_label[i], \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2dad79",
   "metadata": {},
   "source": [
    "#### count number of sentences in train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03cb428b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train_sent 2599\n",
      "length of test_sent 1056\n",
      "length of train_label 2599\n",
      "length of test_label 1056\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"length of train_sent\",len(train_sent))\n",
    "print(\"length of test_sent\",len(test_sent))\n",
    "print(\"length of train_label\",len(train_label))\n",
    "print(\"length of test_label\",len(test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77322ba2",
   "metadata": {},
   "source": [
    "### Extract those tokens which have NOUN or PROPN as their PoS tag and find their frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de8a0add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "\n",
    "def extract_noun_pronoun(sentences):\n",
    "    counter=Counter()\n",
    "    for sentence in sentences:\n",
    "        doc=nlp(sentence)\n",
    "        for token in doc:\n",
    "            if token.pos_=='NOUN' or token.pos_=='PROPN':\n",
    "                counter[token.text]+=1\n",
    "    return counter            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d1f9e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text=train_sent+test_sent\n",
    "all_text_noun_propn_count=extract_noun_pronoun(all_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298bc2f9",
   "metadata": {},
   "source": [
    "\n",
    "### Print the top 25 most common tokens with Noun or propn pos tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ef8d129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('patients', 492)\n",
      "('treatment', 281)\n",
      "('%', 247)\n",
      "('cancer', 200)\n",
      "('therapy', 175)\n",
      "('study', 154)\n",
      "('disease', 142)\n",
      "('cell', 140)\n",
      "('lung', 116)\n",
      "('group', 94)\n",
      "('chemotherapy', 88)\n",
      "('gene', 87)\n",
      "('effects', 85)\n",
      "('women', 77)\n",
      "('results', 77)\n",
      "('use', 75)\n",
      "('risk', 71)\n",
      "('cases', 71)\n",
      "('surgery', 71)\n",
      "('analysis', 70)\n",
      "('rate', 67)\n",
      "('dose', 66)\n",
      "('response', 66)\n",
      "('survival', 65)\n",
      "('children', 64)\n"
     ]
    }
   ],
   "source": [
    "for noun_propn in all_text_noun_propn_count.most_common(25):\n",
    "    print(noun_propn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21caccc",
   "metadata": {},
   "source": [
    "## Defining features for CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd4ccc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sentence,pos,pos_tags):\n",
    "    word=sentence[pos]\n",
    "    \n",
    "    #define features\n",
    "    features={\n",
    "        'bias':1.0,\n",
    "        'word.lower()':word.lower(),\n",
    "        'word[-3:]':word[-3:],\n",
    "        'word[-2:]':word[-2:],\n",
    "        'word.isupper()':word.isupper(),\n",
    "        'word.istitle()':word.istitle(),\n",
    "        'word.isdigit()':word.isdigit(),\n",
    "        'pos':pos_tags[pos]\n",
    "    }\n",
    "    #features for the word preceding the current word\n",
    "    if pos>0:\n",
    "        prev_word=sentence[pos-1]\n",
    "        features.update({\n",
    "            '-1:word.lower()':prev_word.lower(),\n",
    "            '-1:word.istitle()':prev_word.istitle(),\n",
    "            '-1:word.isupper()':word.isupper(),\n",
    "            '-1:pos':pos_tags[pos-1]\n",
    "        })\n",
    "    else:\n",
    "            #Indicate that it is the 'begining of a document'\n",
    "            features['BOS']=True\n",
    "    #Features for the word succeeding the current word\n",
    "    if pos < len(sentence) -1:\n",
    "        next_word=sentence[pos+1]\n",
    "        features.update({\n",
    "            '+1:word.lower()':next_word.lower(),\n",
    "            '+1:word.istitle()':next_word.istitle(),\n",
    "            '+1:word.isupper()':word.isupper(),\n",
    "            '+1:pos':pos_tags[pos+1]\n",
    "        })\n",
    "    else:   \n",
    "        #Indicates that it is the 'end of document'\n",
    "        features['EOS']=True\n",
    "    return features    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09da93d8",
   "metadata": {},
   "source": [
    "## Getting the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea40d12",
   "metadata": {},
   "source": [
    "### Write a code/function to get the features for a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e777678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to get features for a sentence using the 'get features for one word' function\n",
    "def sent2features(sentence):\n",
    "    processed_sentence=nlp(sentence)# spacy is applied to sentence\n",
    "    \n",
    "    pos_tags=[]# identify pos tags\n",
    "    for token in processed_sentence:\n",
    "        pos_tags.append(token.pos_)\n",
    "    sentence_list=sentence.split()  # list of words in sentence\n",
    "    \n",
    "    #calling getfeatures for oneword defined above\n",
    "    return [word2features(sentence_list,pos,pos_tags) for pos in range(len(sentence_list))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9ae0f8",
   "metadata": {},
   "source": [
    "### Write a code/function to get the labels of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5619b402",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a code to get the labels for a sentence\n",
    "def get_labels(labels):\n",
    "    return labels.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fed97d",
   "metadata": {},
   "source": [
    "## Define input and target variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb81bd2",
   "metadata": {},
   "source": [
    "### Define the features values for each sentence as input variable  for CRF model in test and the train dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e73addb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[sent2features(sentence) for sentence in train_sent]\n",
    "X_test=[sent2features(sentence) for sentence in test_sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd4dd948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example train:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bias': 1.0,\n",
       " 'word.lower()': 'all',\n",
       " 'word[-3:]': 'All',\n",
       " 'word[-2:]': 'll',\n",
       " 'word.isupper()': False,\n",
       " 'word.istitle()': True,\n",
       " 'word.isdigit()': False,\n",
       " 'pos': 'DET',\n",
       " 'BOS': True,\n",
       " '+1:word.lower()': 'live',\n",
       " '+1:word.istitle()': False,\n",
       " '+1:word.isupper()': False,\n",
       " '+1:pos': 'ADJ'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'bias': 1.0,\n",
       " 'word.lower()': 'live',\n",
       " 'word[-3:]': 'ive',\n",
       " 'word[-2:]': 've',\n",
       " 'word.isupper()': False,\n",
       " 'word.istitle()': False,\n",
       " 'word.isdigit()': False,\n",
       " 'pos': 'ADJ',\n",
       " '-1:word.lower()': 'all',\n",
       " '-1:word.istitle()': True,\n",
       " '-1:word.isupper()': False,\n",
       " '-1:pos': 'DET',\n",
       " '+1:word.lower()': 'births',\n",
       " '+1:word.istitle()': False,\n",
       " '+1:word.isupper()': False,\n",
       " '+1:pos': 'NOUN'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "==================================================\n",
      "Examples test:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bias': 1.0,\n",
       " 'word.lower()': 'furthermore',\n",
       " 'word[-3:]': 'ore',\n",
       " 'word[-2:]': 're',\n",
       " 'word.isupper()': False,\n",
       " 'word.istitle()': True,\n",
       " 'word.isdigit()': False,\n",
       " 'pos': 'ADV',\n",
       " 'BOS': True,\n",
       " '+1:word.lower()': ',',\n",
       " '+1:word.istitle()': False,\n",
       " '+1:word.isupper()': False,\n",
       " '+1:pos': 'PUNCT'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'bias': 1.0,\n",
       " 'word.lower()': ',',\n",
       " 'word[-3:]': ',',\n",
       " 'word[-2:]': ',',\n",
       " 'word.isupper()': False,\n",
       " 'word.istitle()': False,\n",
       " 'word.isdigit()': False,\n",
       " 'pos': 'PUNCT',\n",
       " '-1:word.lower()': 'furthermore',\n",
       " '-1:word.istitle()': True,\n",
       " '-1:word.isupper()': False,\n",
       " '-1:pos': 'ADV',\n",
       " '+1:word.lower()': 'when',\n",
       " '+1:word.istitle()': False,\n",
       " '+1:word.isupper()': False,\n",
       " '+1:pos': 'SCONJ'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Example train:\")\n",
    "display(X_train[0][0])\n",
    "display(X_train[0][1])\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"Examples test:\")\n",
    "display(X_test[0][0])\n",
    "display(X_test[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200bd305",
   "metadata": {},
   "source": [
    "### Define the labels as the target variable for test and the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9dfde78",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [get_labels(labels) for labels in train_label]\n",
    "y_test = [get_labels(labels) for labels in test_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25ee74c",
   "metadata": {},
   "source": [
    "## Build the CRF Model\n",
    "\n",
    "Parameters chosen:\n",
    "\n",
    "- algorithm='lbfgs': The algorithm parameter specifies the training algorithm used for optimization. lbfgs stands for Limited-memory Broyden-Fletcher-Goldfarb-Shanno, which is an optimization algorithm in the family of quasi-Newton methods that approximates the Broyden-Fletcher-Goldfarb-Shanno algorithm using a limited amount of computer memory. It's a popular choice for optimization problems.\n",
    "\n",
    "- c1=0.1 and c2=0.1: These are regularization parameters. Regularization is a technique used to prevent overfitting by adding a penalty term to the objective function. The c1 parameter is for L1 regularization and c2 is for L2 regularization. L1 can lead to sparsity (i.e., some of the feature weights will be zero), which can be beneficial if you have a lot of features and believe that many of them are irrelevant. L2 encourages the weights to be small but doesn't force them to zero. The specific values 0.1 are a common starting point, but these should be tuned for your specific problem. You might want to perform a hyperparameter search or cross-validation to find the best values.\n",
    "\n",
    "- max_iterations=100: The max_iterations parameter specifies the maximum number of iterations for the optimizer. This means the optimization process (the learning process) will run for 100 iterations at most. If the best weights for the features are found before 100 iterations, the process will stop early.\n",
    "\n",
    "- all_possible_transitions=True: The all_possible_transitions parameter, when set to True, creates additional transition features that are not present in the data. This can potentially improve the performance by capturing the transitions that haven't been seen in the training data but might be in the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e23d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CRF model\n",
    "from sklearn_crfsuite import CRF\n",
    " \n",
    "# Define the model\n",
    "crf=CRF(algorithm='lbfgs',# gradient descent using the L-BFGS method\n",
    "       c1=0.1,# coefficient for l1 regularization\n",
    "       c2=0.1,# coefficient for l2 regularization\n",
    "       max_iterations=100,#maximum number of iterations for the optimizer\n",
    "       all_possible_transitions=True)  # Whether to include transitions that are not present in the data\n",
    "try:\n",
    "    crf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d4d642",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaa1e97",
   "metadata": {},
   "source": [
    "### Predict the labels of each of the tokens in each sentence of the test dataset that has been pre processed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "556de7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb48d6d",
   "metadata": {},
   "source": [
    "### Calculate the f1 score using the actual labels and the predicted labels of the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e55f11f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.927000918447066"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.flat_f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b615579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_diseases_treatments(sentences, predicted_labels):\n",
    "    \"\"\"\n",
    "    This function extracts diseases and their corresponding treatments from the sentences\n",
    "    using the predicted labels and returns them in a dictionary.\n",
    "\n",
    "    :param sentences: List of sentences\n",
    "    :param predicted_labels: List of lists of labels for each sentence\n",
    "    :return: A dictionary where keys are diseases and values are lists of treatments\n",
    "    \"\"\"\n",
    "    disease_treatment_dict = {}  # Initialize an empty dictionary\n",
    "\n",
    "    # For each sentence and its corresponding labels\n",
    "    for sent, labels in zip(sentences, predicted_labels):\n",
    "        disease = \"\"  # Initialize disease as an empty string\n",
    "        treatment = \"\"  # Initialize treatment as an empty string\n",
    "\n",
    "        words = sent.split()\n",
    "\n",
    "        # For each word and its corresponding label\n",
    "        for word, label in zip(words, labels):\n",
    "            if label == 'O':  # Ignore if label is 'O'\n",
    "                continue\n",
    "            elif label == 'D':  # If label is 'D', add the word to disease\n",
    "                disease += word.lower() + \" \"\n",
    "            elif label == 'T':  # If label is 'T', add the word to treatment\n",
    "                treatment += word.lower() + \" \"\n",
    "\n",
    "        disease = disease.strip()  # Remove leading/trailing spaces\n",
    "        treatment = treatment.strip()  # Remove leading/trailing spaces\n",
    "\n",
    "        # If both disease and treatment are not empty\n",
    "        if disease and treatment:\n",
    "            # If disease is not in the dictionary, add it\n",
    "            if disease not in disease_treatment_dict:\n",
    "                disease_treatment_dict[disease] = [treatment]\n",
    "            # If disease is already in the dictionary, append the treatment\n",
    "            else:\n",
    "                disease_treatment_dict[disease].append(treatment)\n",
    "\n",
    "    return disease_treatment_dict\n",
    "\n",
    "  \n",
    "def find_treatments_for_disease(disease_treatment_dict, keyword):\n",
    "  \"\"\"\n",
    "  This function looks for a disease that contains a certain keyword in the dictionary and \n",
    "  returns a dictionary with those diseases and their corresponding treatments.\n",
    "\n",
    "  :param disease_treatment_dict: A dictionary where keys are diseases and values are lists of treatments\n",
    "  :param keyword: The keyword to search for in the diseases\n",
    "  :return: A dictionary where keys are diseases containing the keyword and values are lists of treatments\n",
    "  \"\"\"\n",
    "  return {disease: treatments for disease, treatments in disease_treatment_dict.items() if keyword in disease}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ce4d82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'retinoblastoma': ['radiotherapy']}\n"
     ]
    }
   ],
   "source": [
    "disease_treatment_dict = extract_diseases_treatments(test_sent, y_pred)\n",
    "\n",
    "retinoblastoma_treatments = find_treatments_for_disease(disease_treatment_dict, \"retinoblastoma\")\n",
    "print(retinoblastoma_treatments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed66e7c",
   "metadata": {},
   "source": [
    "# Let's check another disease such as diseases with the word \"cerebral\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89d14744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acute occlusion of the middle cerebral artery': ['thrombolytic therapy'],\n",
       " 'acute cerebral ischemia': ['antiplatelet therapy'],\n",
       " 'cerebral palsy': ['hyperbaric oxygen therapy']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_treatments_for_disease(disease_treatment_dict, \"cerebral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49afc3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
